# Environment Variables for AI Service

# Server Configuration
PORT=8000
HOST=0.0.0.0
WORKERS=1

# AI Service APIs (Gemini only)
GEMINI_API_KEY=your-gemini-api-key-here

# AI Model Configuration
GEMINI_MODEL=gemini-pro
DEFAULT_AI_PROVIDER=gemini

# Request Limits
MAX_CONTENT_LENGTH=10000  # characters
MAX_QUESTIONS_PER_REQUEST=50
MAX_REQUEST_SIZE=10485760  # 10MB

# AI Generation Settings
DEFAULT_TEMPERATURE=0.7
MAX_TOKENS=2000
TIMEOUT_SECONDS=60

# Firebase Admin (for user verification)
FIREBASE_PROJECT_ID=your-firebase-project-id
FIREBASE_SERVICE_ACCOUNT_KEY={}

# Content Processing
PDF_MAX_SIZE=50485760  # 50MB
ALLOWED_FILE_TYPES=pdf,txt,docx
TEXT_EXTRACTION_METHOD=pdfplumber  # pdfplumber, pypdf2, ocr

# NLP Configuration
SPACY_MODEL=en_core_web_sm
NLTK_DATA_PATH=./nltk_data
USE_GPU=false

# Caching
CACHE_ENABLED=true
CACHE_TTL=3600  # 1 hour
REDIS_URL=redis://localhost:6379

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=./logs/ai-service.log

# Performance
ASYNC_BATCH_SIZE=5
MAX_CONCURRENT_REQUESTS=10
PRELOAD_MODELS=true

# Fallback Configuration
ENABLE_FALLBACK=true
FALLBACK_TIMEOUT=5  # seconds before falling back

# Development
DEBUG=false
MOCK_AI_RESPONSES=false  # Use mock responses instead of actual AI APIs
BYPASS_AUTH=false
